{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19985e3d-9ed9-4e96-b05c-aa7d9a905c7c",
   "metadata": {},
   "source": [
    "# RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06367b46",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9753de-2fa5-4bb9-ab23-f1a54bfc80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src import stats, plotting, temporal, decoding, rsa\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c656b620-1fbb-4937-9143-ca6439428264",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'pseudo010'\n",
    "process = 'EEG_RSA'\n",
    "eeg_metric = 'decoding'\n",
    "fmri_metric = 'decoding'\n",
    "regress_gaze = False\n",
    "\n",
    "run_splithalf_reliability = True\n",
    "run_fmri_rsa = True\n",
    "run_feature_decoding = True\n",
    "run_feature_rsa = True\n",
    "\n",
    "top_path = '/Users/emcmaho7/Dropbox/projects/SI_EEG/SIEEG_analysis'\n",
    "data_dir = f'{top_path}/data'\n",
    "figure_dir = f'{top_path}/reports/figures/{process}/{subj}'\n",
    "\n",
    "Path(figure_dir).mkdir(exist_ok=True, parents=True)\n",
    "Path(f'{data_dir}/interim/{process}').mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c9786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ['EVC', 'MT', 'EBA',\n",
    "        'LOC', 'FFA', 'PPA',\n",
    "        'pSTS', 'face-pSTS', 'aSTS']\n",
    "features = ['alexnet', 'moten', 'indoor',\n",
    "                 'expanse', 'object_directedness', 'agent_distance',\n",
    "                 'facingness', 'joint_action', 'communication', \n",
    "                 'valence', 'arousal']\n",
    "annotated_features = ['indoor', 'expanse', 'object_directedness', \n",
    "                 'agent_distance', 'facingness', 'joint_action', \n",
    "                 'communication', 'valence', 'arousal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{data_dir}/interim/PreprocessData/{subj}_reg-gaze-{regress_gaze}.csv.gz')\n",
    "all_cols = set(df.columns.to_list())\n",
    "other_cols = set(['trial', 'time', 'offset', 'offset_eyetrack_x', 'video_name',\n",
    "              'gaze_x', 'gaze_y', 'pupil_size', 'target_x', 'target_y',\n",
    "               'target_distance', 'offset_eyetrack_y', 'repetition', 'even', 'session'])\n",
    "channels = list(all_cols - other_cols)\n",
    "feature_df = pd.read_csv(f'{data_dir}/interim/FeatureRDMs/feature_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17996a8",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_feature_decoding: \n",
    "    videos = np.array(feature_df['video_name'])\n",
    "    df_avg = df.groupby(['time', 'video_name']).mean(numeric_only=True).reset_index()\n",
    "    cols_to_drop = set(df.columns.to_list()) - set(['time', 'video_name'] + channels)\n",
    "    df_avg.drop(columns=cols_to_drop, inplace=True)\n",
    "    df_avg.sort_values(['time', 'video_name'], inplace=True)\n",
    "    df_avg = temporal.smoothing(df_avg, 'video_name')\n",
    "\n",
    "    results = decoding.eeg_feature_decoding(df_avg, feature_df,\n",
    "                                            annotated_features, channels)\n",
    "    results.to_csv(f'{data_dir}/interim/{process}/{subj}_feature_EEG_reg-gaze-{regress_gaze}_decoding.csv', index=False)\n",
    "\n",
    "    out_file = f'{figure_dir}/{subj}_feature_EEG_reg-gaze-{regress_gaze}_decoding.png'\n",
    "    plotting.plot_eeg_feature_decoding(out_file, results, annotated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gaze_x' in df.columns:\n",
    "    avg_df = df.groupby(['video_name', 'time']).mean().reset_index()\n",
    "    gaze_df = avg_df.loc[(avg_df.time > 0) & (avg_df.time <= .5)]\n",
    "    X = np.hstack([gaze_df.pivot(index='video_name', columns='time', values='gaze_x').to_numpy(),\n",
    "                gaze_df.pivot(index='video_name', columns='time', values='gaze_y').to_numpy()])\n",
    "\n",
    "    results = decoding.gaze_feature_decoding(X, feature_df, annotated_features, gaze_df.video_name.to_list())\n",
    "    print(results)\n",
    "    results['subj'] = subj\n",
    "    results.to_csv(f'{data_dir}/interim/{process}/{subj}_feature_gaze_decoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
