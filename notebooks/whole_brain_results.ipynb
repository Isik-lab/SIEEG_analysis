{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eee03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac1014d-a0b6-4fb8-9850-ee50867113ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from src import plotting\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15735218-fc3b-4e28-9d81-26b6565e25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = 'Group_Analysis'\n",
    "top_path = '/Users/emcmaho7/Dropbox/projects/SI_EEG/SIEEG_analysis'\n",
    "input_path = f'{top_path}/data/interim'\n",
    "out_path = f'{top_path}/data/interim/{process}'\n",
    "figure_path = f'{top_path}/reports/figures/{process}'\n",
    "Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(figure_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "regress_gaze = False\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0234183-b3c3-4269-b41f-1b0a0974b85f",
   "metadata": {},
   "source": [
    "## fMRI Whole Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d17bc8-4ea6-48a8-9231-27275c061b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn import plotting, surface\n",
    "import nibabel as nib\n",
    "from src.tools import camera_switcher\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "os.environ[\"SUBJECTS_DIR\"] = \"/Users/emcmaho7/Dropbox/projects/SI_EEG/SIEEG_analysis/data/raw/freesurfer\"\n",
    "os.environ[\"FREESURFER_HOME\"] = \"/Applications/freesurfer\"\n",
    "\n",
    "\n",
    "def compute_surf_stats(prefix, sub, hemi):\n",
    "    file = f'{prefix}_hemi-{hemi}.mgz'\n",
    "    if not os.path.exists(file):\n",
    "        cmd = '/Applications/freesurfer/bin/mri_vol2surf '\n",
    "        cmd += f'--src {prefix}.nii.gz '\n",
    "        cmd += f'--out {file} '\n",
    "        cmd += f'--regheader sub-{sub} '\n",
    "        cmd += f'--hemi {hemi} '\n",
    "        cmd += '--projfrac 1 '\n",
    "        cmd += '> /dev/null 2>&1'\n",
    "        os.system(cmd)\n",
    "    return surface.load_surf_data(file)\n",
    "\n",
    "\n",
    "def load_surf_mesh(path, sub, hemi):\n",
    "    return f'{path}/freesurfer/sub-{sub}/surf/{hemi}.inflated', \\\n",
    "            f'{path}/freesurfer/sub-{sub}/surf/{hemi}.sulc'\n",
    "\n",
    "\n",
    "def plot_stats(surf_mesh, bg_map, surf_map, hemi_, figure_prefix,\n",
    "               vmax=0.3, threshold=1e-6, \n",
    "               title=None, cmap_name='magma', \n",
    "               views=['ventral', 'medial', 'lateral']):\n",
    "    cmap=sns.color_palette(cmap_name, as_cmap=True)\n",
    "    hemi_name = 'left' if hemi_ == 'lh' else 'right'\n",
    "    \n",
    "    for view in views:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"choosing both vmin and a threshold is not allowed; setting vmin to 0\")\n",
    "            fig = plotting.plot_surf_roi(surf_mesh=surf_mesh,\n",
    "                                        roi_map=surf_map,\n",
    "                                        bg_map=bg_map,\n",
    "                                        vmax=vmax,\n",
    "                                        vmin=0., \n",
    "                                        engine='plotly',\n",
    "                                        colorbar=True,\n",
    "                                        view=view,\n",
    "                                        cmap=cmap,\n",
    "                                        title=title,\n",
    "                                        title_font_size=30,\n",
    "                                        hemi=hemi_name)\n",
    "            fig.figure.update_layout(coloraxis_colorbar=dict(\n",
    "                                    title='Explained variance ($r^2$)',\n",
    "                                    tickvals=[0, vmax],  # Positions of the ticks\n",
    "                                    ticktext=list(np.linspace(0, vmax, 4).round(2)),\n",
    "                                    thickness=25,\n",
    "                                    len=0.75,\n",
    "                                    x=1.02),\n",
    "                                     scene_camera=camera_switcher(hemi_, view))\n",
    "            fig.figure.write_image(f'{figure_prefix}_view-{view}_hemi-{hemi_}.png')\n",
    "\n",
    "\n",
    "def pngs_to_mp4(input_folder, output_file,\n",
    "                file_pattern, fps=9, frame_size=None,\n",
    "                start_frame=None, end_frame=None):\n",
    "    \"\"\"\n",
    "    Converts a series of PNG images in a folder into an MP4 video file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the folder containing PNG images.\n",
    "    - output_file: Path to save the MP4 video file.\n",
    "    - fps: Frames per second in the output video.\n",
    "    - frame_size: Tuple of (width, height) for the video frame size. If None, the size of the first image is used.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all the PNG files in the folder\n",
    "    images = glob(os.path.join(input_folder, file_pattern))\n",
    "    images = sorted(images)  # Sort the images by name\n",
    "    if start_frame is not None and end_frame is not None: \n",
    "        images = [image for image in images if start_frame < int(re.search(\"timepoint-(\\d+)\", image).group(1)) < end_frame]\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "    if not frame_size:\n",
    "        # If frame size is not specified, use the first image to determine the size\n",
    "        first_image = cv2.imread(images[0])\n",
    "        frame_size = (first_image.shape[1], first_image.shape[0])\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, frame_size)\n",
    "\n",
    "    for image_path in images:\n",
    "        img = cv2.imread(image_path)\n",
    "        # Resize the image to match the frame size, if necessary\n",
    "        if img.shape[1] != frame_size[0] or img.shape[0] != frame_size[1]:\n",
    "            img = cv2.resize(img, frame_size)\n",
    "        out.write(img)\n",
    "\n",
    "    # Release everything when the job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916afc1-cb76-4d9c-9ac2-feefe761e80e",
   "metadata": {},
   "source": [
    "**Combine Whole Brain results across EEG subjects**\n",
    "\n",
    "**THIS IS VERY SLOW**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6da531-4056-4acd-b148-290d4c050a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_brain_files = glob(f'{out_path}/sub-*_whole-brain-group.csv.gz')\n",
    "if len(whole_brain_files) != 4: \n",
    "    files = sorted(glob(f'{input_path}/fMRIDecoding/sub-*_reg-gaze-False_time-*_whole-brain-decoding.csv.gz'))\n",
    "    df = []\n",
    "    for file in tqdm(files, total=len(files), desc='Loading whole brain results'):\n",
    "        df.append(pd.read_csv(file))\n",
    "    df = pd.concat(df)\n",
    "\n",
    "    df = df.groupby(['subj_id', 'time', 'voxel_id']).mean(numeric_only=True).reset_index()\n",
    "    for id, time_df in tqdm(df.groupby('subj_id'), total=len(df.subj_id.unique()), desc='Saving fMRI subj'):\n",
    "        time_df.to_csv(f'{out_path}/sub-{str(id).zfill(2)}_whole-brain-group.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1921a65d-7ed3-4155-ba8d-5fabc6e4780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_subj = 2\n",
    "start, end = -.1, .75\n",
    "raw_path = f'{top_path}/data/raw'\n",
    "subj_id = str(plotting_subj).zfill(2)\n",
    "Path(f'{input_path}/{process}/brain_plots').mkdir(parents=True, exist_ok=True)\n",
    "Path(f'{figure_path}/brain_plots').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "time_df = pd.read_csv(f'{out_path}/sub-{str(plotting_subj).zfill(2)}_whole-brain-group.csv.gz')\n",
    "time_df[['i_index', 'j_index', 'k_index']] = time_df[['i_index', 'j_index', 'k_index']].astype('int')\n",
    "time_df = time_df.loc[(time_df.time > start) & (time_df.time < end)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950d758e-1ee5-4012-90ea-32c1d5b7394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting subjects: 100%|████████████████████████| 44/44 [28:37<00:00, 39.03s/it]\n"
     ]
    }
   ],
   "source": [
    "hemis = ['lh', 'rh']\n",
    "views = ['ventral', 'medial', 'lateral']\n",
    "\n",
    "time_iterator = tqdm(enumerate(time_df.groupby('time')), total=len(time_df.time.unique()), desc='Plotting subjects')\n",
    "for i, (time, cur_df) in time_iterator:\n",
    "    title = f'{time * 1000:.0f} ms' \n",
    "    time_point = str(i).zfill(3)\n",
    "    stat_file = f'{input_path}/{process}/brain_plots/sub-{subj_id}_timepoint-{time_point}'\n",
    "    plot_file = f'{figure_path}/brain_plots/sub-{subj_id}_timepoint-{time_point}'\n",
    "\n",
    "    img = nib.load(f'{raw_path}/fmri_betas/sub-{subj_id}_space-T1w_desc-train-fracridge_data.nii.gz')\n",
    "\n",
    "    dims = img.shape[:-1]\n",
    "    header, affine = img.header, img.affine\n",
    "\n",
    "    scores_arr = cur_df['r2'].to_numpy()\n",
    "    scores_arr[scores_arr < 0.] = 1e-5 #Threshold at 0 for plotting\n",
    "    indices = cur_df[['i_index', 'j_index', 'k_index']].to_numpy()\n",
    "\n",
    "    score_img = np.zeros(dims)\n",
    "    score_img[indices[:, 0], indices[:, 1], indices[:, 2]] = scores_arr\n",
    "    score_img = nib.Nifti1Image(score_img, affine=affine, header=header)\n",
    "    nib.save(score_img, f'{stat_file}.nii.gz')\n",
    "\n",
    "    for hemi in hemis:\n",
    "        surf = compute_surf_stats(stat_file, subj_id, hemi)\n",
    "        inflated, sulcus = load_surf_mesh(raw_path, subj_id, hemi)\n",
    "        plot_stats(inflated, sulcus, surf, hemi, plot_file,\n",
    "                   title=title, cmap_name='rocket',\n",
    "                   views=views, vmax=.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3d3677-e9d1-4bf8-8c48-1e8b551379c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hemi in hemis: \n",
    "    for view in views:\n",
    "        output_file = f'{figure_path}/sub-{str(plotting_subj).zfill(2)}_view-{view}_hemi-{hemi}.mp4'\n",
    "        file_pattern = f'sub-{str(plotting_subj).zfill(2)}*view-{view}*hemi-{hemi}*.png'\n",
    "        pngs_to_mp4(input_folder=f'{figure_path}/brain_plots',\n",
    "                    output_file=output_file, fps=6,\n",
    "                    file_pattern=file_pattern, start_frame=6, end_frame=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31476137-7faa-4a82-bfea-7f48726643b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibabel",
   "language": "python",
   "name": "nibabel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
